==========================================
SLURM_JOB_ID = 661170
SLURM_NODELIST = gnode14
SLURM_JOB_GPUS = 0,2,3
==========================================
/home2/prateekj/miniconda3/envs/myenv/lib/python3.7/site-packages/dgl/heterograph.py:72: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning('Recommend creating graphs by `dgl.graph(data)`'
/home2/prateekj/miniconda3/envs/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home2/prateekj/miniconda3/envs/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home2/prateekj/miniconda3/envs/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home2/prateekj/miniconda3/envs/myenv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
Classifer(
  (gcn1): SAGEMeanConv(
    (feat_drop): Dropout(p=0.5, inplace=False)
  )
  (gcn2): SAGEMeanConv(
    (feat_drop): Dropout(p=0.5, inplace=False)
  )
)
[2022/4/26 12:08:48] Epoch: 1, train_loss= 3.43340, train_acc= 0.03339, val_loss= 3.00883, val_acc= 0.09107, time= 0.51654
[2022/4/26 12:08:48] Epoch: 2, train_loss= 3.08269, train_acc= 0.10527, val_loss= 2.98327, val_acc= 0.17507, time= 0.08396
[2022/4/26 12:08:48] Epoch: 3, train_loss= 2.82327, train_acc= 0.21006, val_loss= 2.96210, val_acc= 0.26790, time= 0.08180
[2022/4/26 12:08:48] Epoch: 4, train_loss= 2.61481, train_acc= 0.33075, val_loss= 2.94349, val_acc= 0.38727, time= 0.07816
[2022/4/26 12:08:48] Epoch: 5, train_loss= 2.43818, train_acc= 0.44319, val_loss= 2.92684, val_acc= 0.47480, time= 0.07893
[2022/4/26 12:08:48] Epoch: 6, train_loss= 2.28582, train_acc= 0.55141, val_loss= 2.91237, val_acc= 0.56676, time= 0.07569
[2022/4/26 12:08:48] Epoch: 7, train_loss= 2.15517, train_acc= 0.62722, val_loss= 2.90032, val_acc= 0.63218, time= 0.07742
[2022/4/26 12:08:49] Epoch: 8, train_loss= 2.04766, train_acc= 0.68320, val_loss= 2.89131, val_acc= 0.66401, time= 0.07643
[2022/4/26 12:08:49] Epoch: 9, train_loss= 1.96720, train_acc= 0.71924, val_loss= 2.88504, val_acc= 0.69142, time= 0.07665
[2022/4/26 12:08:49] Epoch: 10, train_loss= 1.91252, train_acc= 0.73741, val_loss= 2.88057, val_acc= 0.70999, time= 0.07578
[2022/4/26 12:08:49] Epoch: 11, train_loss= 1.87586, train_acc= 0.74752, val_loss= 2.87708, val_acc= 0.72060, time= 0.07720
[2022/4/26 12:08:49] Epoch: 12, train_loss= 1.84944, train_acc= 0.75381, val_loss= 2.87402, val_acc= 0.72767, time= 0.07625
[2022/4/26 12:08:49] Epoch: 13, train_loss= 1.82835, train_acc= 0.75911, val_loss= 2.87113, val_acc= 0.73740, time= 0.07621
[2022/4/26 12:08:49] Epoch: 14, train_loss= 1.80955, train_acc= 0.76677, val_loss= 2.86823, val_acc= 0.75332, time= 0.07599
[2022/4/26 12:08:49] Epoch: 15, train_loss= 1.79043, train_acc= 0.77816, val_loss= 2.86522, val_acc= 0.76481, time= 0.07650
[2022/4/26 12:08:49] Epoch: 16, train_loss= 1.77022, train_acc= 0.78562, val_loss= 2.86247, val_acc= 0.77454, time= 0.07562
[2022/4/26 12:08:49] Epoch: 17, train_loss= 1.75116, train_acc= 0.79132, val_loss= 2.86049, val_acc= 0.77630, time= 0.07515
[2022/4/26 12:08:49] Epoch: 18, train_loss= 1.73640, train_acc= 0.79309, val_loss= 2.85932, val_acc= 0.77630, time= 0.07724
[2022/4/26 12:08:49] Epoch: 19, train_loss= 1.72770, train_acc= 0.79318, val_loss= 2.85870, val_acc= 0.77630, time= 0.07650
[2022/4/26 12:08:49] Epoch: 20, train_loss= 1.72383, train_acc= 0.79318, val_loss= 2.85832, val_acc= 0.77630, time= 0.07697
[2022/4/26 12:08:50] Epoch: 21, train_loss= 1.72199, train_acc= 0.79318, val_loss= 2.85801, val_acc= 0.77630, time= 0.07714
[2022/4/26 12:08:50] Epoch: 22, train_loss= 1.72055, train_acc= 0.79318, val_loss= 2.85774, val_acc= 0.77630, time= 0.07804
[2022/4/26 12:08:50] Epoch: 23, train_loss= 1.71918, train_acc= 0.79318, val_loss= 2.85751, val_acc= 0.77630, time= 0.07744
[2022/4/26 12:08:50] Epoch: 24, train_loss= 1.71803, train_acc= 0.79318, val_loss= 2.85734, val_acc= 0.77630, time= 0.07723
[2022/4/26 12:08:50] Epoch: 25, train_loss= 1.71717, train_acc= 0.79318, val_loss= 2.85721, val_acc= 0.77630, time= 0.07588
[2022/4/26 12:08:50] Epoch: 26, train_loss= 1.71654, train_acc= 0.79318, val_loss= 2.85711, val_acc= 0.77630, time= 0.07683
[2022/4/26 12:08:50] Epoch: 27, train_loss= 1.71607, train_acc= 0.79318, val_loss= 2.85703, val_acc= 0.77630, time= 0.07622
[2022/4/26 12:08:50] Epoch: 28, train_loss= 1.71573, train_acc= 0.79318, val_loss= 2.85696, val_acc= 0.77630, time= 0.07643
[2022/4/26 12:08:50] Epoch: 29, train_loss= 1.71550, train_acc= 0.79318, val_loss= 2.85692, val_acc= 0.77630, time= 0.07659
[2022/4/26 12:08:50] Epoch: 30, train_loss= 1.71534, train_acc= 0.79318, val_loss= 2.85688, val_acc= 0.77630, time= 0.07691
[2022/4/26 12:08:50] Epoch: 31, train_loss= 1.71522, train_acc= 0.79318, val_loss= 2.85684, val_acc= 0.77630, time= 0.07649
[2022/4/26 12:08:50] Epoch: 32, train_loss= 1.71514, train_acc= 0.79318, val_loss= 2.85682, val_acc= 0.77630, time= 0.07589
[2022/4/26 12:08:50] Epoch: 33, train_loss= 1.71507, train_acc= 0.79318, val_loss= 2.85679, val_acc= 0.77630, time= 0.07776
[2022/4/26 12:08:51] Epoch: 34, train_loss= 1.71501, train_acc= 0.79318, val_loss= 2.85678, val_acc= 0.77630, time= 0.07664
[2022/4/26 12:08:51] Epoch: 35, train_loss= 1.71496, train_acc= 0.79318, val_loss= 2.85676, val_acc= 0.77630, time= 0.07629
[2022/4/26 12:08:51] Epoch: 36, train_loss= 1.71492, train_acc= 0.79318, val_loss= 2.85675, val_acc= 0.77630, time= 0.07701
[2022/4/26 12:08:51] Epoch: 37, train_loss= 1.71488, train_acc= 0.79318, val_loss= 2.85673, val_acc= 0.77630, time= 0.07731
[2022/4/26 12:08:51] Epoch: 38, train_loss= 1.71485, train_acc= 0.79318, val_loss= 2.85672, val_acc= 0.77630, time= 0.07700
[2022/4/26 12:08:51] Epoch: 39, train_loss= 1.71483, train_acc= 0.79318, val_loss= 2.85671, val_acc= 0.77630, time= 0.07724
[2022/4/26 12:08:51] Epoch: 40, train_loss= 1.71480, train_acc= 0.79318, val_loss= 2.85671, val_acc= 0.77630, time= 0.07725
[2022/4/26 12:08:51] Epoch: 41, train_loss= 1.71478, train_acc= 0.79318, val_loss= 2.85670, val_acc= 0.77630, time= 0.07586
[2022/4/26 12:08:51] Epoch: 42, train_loss= 1.71477, train_acc= 0.79318, val_loss= 2.85669, val_acc= 0.77630, time= 0.07741
[2022/4/26 12:08:51] Epoch: 43, train_loss= 1.71475, train_acc= 0.79318, val_loss= 2.85669, val_acc= 0.77630, time= 0.07620
[2022/4/26 12:08:51] Epoch: 44, train_loss= 1.71474, train_acc= 0.79318, val_loss= 2.85668, val_acc= 0.77630, time= 0.07640
[2022/4/26 12:08:51] Epoch: 45, train_loss= 1.71473, train_acc= 0.79318, val_loss= 2.85668, val_acc= 0.77630, time= 0.07698
[2022/4/26 12:08:51] Epoch: 46, train_loss= 1.71472, train_acc= 0.79318, val_loss= 2.85667, val_acc= 0.77630, time= 0.07667
[2022/4/26 12:08:52] Epoch: 47, train_loss= 1.71471, train_acc= 0.79318, val_loss= 2.85667, val_acc= 0.77630, time= 0.07715
[2022/4/26 12:08:52] Epoch: 48, train_loss= 1.71470, train_acc= 0.79318, val_loss= 2.85667, val_acc= 0.77630, time= 0.07702
[2022/4/26 12:08:52] Epoch: 49, train_loss= 1.71469, train_acc= 0.79318, val_loss= 2.85667, val_acc= 0.77630, time= 0.07684
[2022/4/26 12:08:52] Epoch: 50, train_loss= 1.71468, train_acc= 0.79318, val_loss= 2.85666, val_acc= 0.77630, time= 0.07826
[2022/4/26 12:08:52] Epoch: 51, train_loss= 1.71468, train_acc= 0.79318, val_loss= 2.85666, val_acc= 0.77630, time= 0.07670
[2022/4/26 12:08:52] Epoch: 52, train_loss= 1.71467, train_acc= 0.79318, val_loss= 2.85666, val_acc= 0.77630, time= 0.07616
[2022/4/26 12:08:52] Epoch: 53, train_loss= 1.71467, train_acc= 0.79318, val_loss= 2.85666, val_acc= 0.77630, time= 0.07655
[2022/4/26 12:08:52] Epoch: 54, train_loss= 1.71466, train_acc= 0.79318, val_loss= 2.85666, val_acc= 0.77630, time= 0.07667
[2022/4/26 12:08:52] Epoch: 55, train_loss= 1.71466, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07655
[2022/4/26 12:08:52] Epoch: 56, train_loss= 1.71465, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07571
[2022/4/26 12:08:52] Epoch: 57, train_loss= 1.71465, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07714
[2022/4/26 12:08:52] Epoch: 58, train_loss= 1.71465, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07662
[2022/4/26 12:08:52] Epoch: 59, train_loss= 1.71464, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07754
[2022/4/26 12:08:53] Epoch: 60, train_loss= 1.71464, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07615
[2022/4/26 12:08:53] Epoch: 61, train_loss= 1.71464, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07722
[2022/4/26 12:08:53] Epoch: 62, train_loss= 1.71464, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07722
[2022/4/26 12:08:53] Epoch: 63, train_loss= 1.71463, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07737
[2022/4/26 12:08:53] Epoch: 64, train_loss= 1.71463, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07597
[2022/4/26 12:08:53] Epoch: 65, train_loss= 1.71463, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07813
[2022/4/26 12:08:53] Epoch: 66, train_loss= 1.71463, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07651
[2022/4/26 12:08:53] Epoch: 67, train_loss= 1.71462, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07735
[2022/4/26 12:08:53] Epoch: 68, train_loss= 1.71462, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.08279
[2022/4/26 12:08:53] Epoch: 69, train_loss= 1.71462, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07668
[2022/4/26 12:08:53] Epoch: 70, train_loss= 1.71462, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07689
[2022/4/26 12:08:53] Epoch: 71, train_loss= 1.71462, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07824
[2022/4/26 12:08:53] Epoch: 72, train_loss= 1.71462, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07763
[2022/4/26 12:08:54] Epoch: 73, train_loss= 1.71461, train_acc= 0.79318, val_loss= 2.85665, val_acc= 0.77630, time= 0.07631
[2022/4/26 12:08:54] Early stopping...
[2022/4/26 12:08:54] Optimization Finished!
[2022/4/26 12:08:54] Test set results: 
[2022/4/26 12:08:54] 	 loss= 2.05172, accuracy= 0.79142, time= 0.02694
[2022/4/26 12:08:54] Test Precision, Recall and F1-Score...
[2022/4/26 12:08:54]               precision    recall  f1-score   support
[2022/4/26 12:08:54] 
[2022/4/26 12:08:54]            0     0.2242    1.0000    0.3663       398
[2022/4/26 12:08:54]            1     1.0000    1.0000    1.0000       395
[2022/4/26 12:08:54]            2     0.9945    1.0000    0.9973       364
[2022/4/26 12:08:54]            3     0.0000    0.0000    0.0000       399
[2022/4/26 12:08:54]            4     1.0000    0.9968    0.9984       310
[2022/4/26 12:08:54]            5     1.0000    1.0000    1.0000       396
[2022/4/26 12:08:54]            6     0.8899    1.0000    0.9417       396
[2022/4/26 12:08:54]            7     0.0000    0.0000    0.0000       394
[2022/4/26 12:08:54]            8     0.0000    0.0000    0.0000       392
[2022/4/26 12:08:54]            9     0.9921    1.0000    0.9960       251
[2022/4/26 12:08:54]           10     1.0000    1.0000    1.0000       396
[2022/4/26 12:08:54]           11     1.0000    1.0000    1.0000       376
[2022/4/26 12:08:54]           12     0.9873    1.0000    0.9936       389
[2022/4/26 12:08:54]           13     0.9540    1.0000    0.9765       394
[2022/4/26 12:08:54]           14     1.0000    1.0000    1.0000       398
[2022/4/26 12:08:54]           15     1.0000    1.0000    1.0000       393
[2022/4/26 12:08:54]           16     1.0000    1.0000    1.0000       319
[2022/4/26 12:08:54]           17     0.7724    1.0000    0.8716       397
[2022/4/26 12:08:54]           18     1.0000    1.0000    1.0000       390
[2022/4/26 12:08:54]           19     0.0000    0.0000    0.0000       385
[2022/4/26 12:08:54] 
[2022/4/26 12:08:54]     accuracy                         0.7914      7532
[2022/4/26 12:08:54]    macro avg     0.7407    0.7998    0.7571      7532
[2022/4/26 12:08:54] weighted avg     0.7292    0.7914    0.7463      7532
[2022/4/26 12:08:54] 
[2022/4/26 12:08:54] Macro average Test Precision, Recall and F1-Score...
[2022/4/26 12:08:54] (0.7407210858129474, 0.7998387096774193, 0.7570683204484526, None)
[2022/4/26 12:08:54] Micro average Test Precision, Recall and F1-Score...
[2022/4/26 12:08:54] (0.7914232607541157, 0.7914232607541157, 0.7914232607541157, None)
[2022/4/26 12:08:54] Embeddings:
[2022/4/26 12:08:54] Word_embeddings:39
[2022/4/26 12:08:54] Train_doc_embeddings:11314
[2022/4/26 12:08:54] Test_doc_embeddings:7532
[2022/4/26 12:08:54] Word_embeddings:
[[0.24854927 0.08185401 0.         ... 0.31900164 0.20074984 0.14546649]
 [0.03547871 0.21437554 0.         ... 0.         0.         0.30652517]
 [0.         0.3757369  0.         ... 0.3591931  0.31163123 0.        ]
 ...
 [0.10536573 0.05104867 0.         ... 0.0569098  0.09447179 0.        ]
 [0.2029308  0.18330278 0.         ... 0.32492885 0.17679572 0.        ]
 [0.21196559 0.         0.21045303 ... 0.33618042 0.27112344 0.33054778]]
Traceback (most recent call last):
  File "/home2/prateekj/GNN-for-text-classification/main.py", line 370, in <module>
    word_vector = word_embeddings[i]
IndexError: index 39 is out of bounds for axis 0 with size 39
