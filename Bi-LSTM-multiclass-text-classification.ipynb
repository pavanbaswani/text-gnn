{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Table of Contents</u>\n",
    "*  [1. Reading and Analyzing Dataframe](#1)\n",
    "*  [2. Label Encoding](#2)\n",
    "*  [3. Tokenizing Sentences and Fixing Sentence Length](#3)\n",
    "*  [4. Bi-LSTM Model](#4)\n",
    "*  [5. Model Evaluation](#5)\n",
    "*  [6. References](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "worst-charlotte"
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T10:56:17.177127Z",
     "iopub.status.busy": "2022-04-24T10:56:17.176453Z",
     "iopub.status.idle": "2022-04-24T10:56:17.189033Z",
     "shell.execute_reply": "2022-04-24T10:56:17.1883Z",
     "shell.execute_reply.started": "2022-04-24T10:56:17.177085Z"
    },
    "id": "A9VsJVnuaACm",
    "outputId": "30d3a9ed-86c4-426e-a320-84a4da0ec376"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:26:52.514094Z",
     "iopub.status.busy": "2022-04-24T12:26:52.513481Z",
     "iopub.status.idle": "2022-04-24T12:26:52.518914Z",
     "shell.execute_reply": "2022-04-24T12:26:52.517796Z",
     "shell.execute_reply.started": "2022-04-24T12:26:52.514053Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import sklearn\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dominant-bible"
   },
   "source": [
    "# 1. Reading and Analysing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/text-classification-dataset/hindi/hindi/hindi_train.csv',lineterminator='\\n')\n",
    "dev_df = pd.read_csv('../input/text-classification-dataset/hindi/hindi/hindi_valid.csv',lineterminator='\\n')\n",
    "test_df = pd.read_csv('../input/text-classification-dataset/hindi/hindi/hindi_test.csv',lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:23:25.977766Z",
     "iopub.status.busy": "2022-04-24T11:23:25.977525Z",
     "iopub.status.idle": "2022-04-24T11:23:25.997126Z",
     "shell.execute_reply": "2022-04-24T11:23:25.996468Z",
     "shell.execute_reply.started": "2022-04-24T11:23:25.977733Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=['Unnamed: 0'])\n",
    "dev_df = dev_df.drop(columns=['Unnamed: 0'])\n",
    "test_df = test_df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:23:25.999787Z",
     "iopub.status.busy": "2022-04-24T11:23:25.99938Z",
     "iopub.status.idle": "2022-04-24T11:23:26.004968Z",
     "shell.execute_reply": "2022-04-24T11:23:26.004259Z",
     "shell.execute_reply.started": "2022-04-24T11:23:25.999749Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.columns = ['text', 'label']\n",
    "dev_df.columns = ['text', 'label']\n",
    "test_df.columns = ['text', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:23:28.208811Z",
     "iopub.status.busy": "2022-04-24T11:23:28.20827Z",
     "iopub.status.idle": "2022-04-24T11:23:28.222837Z",
     "shell.execute_reply": "2022-04-24T11:23:28.222152Z",
     "shell.execute_reply.started": "2022-04-24T11:23:28.20877Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:23:28.724249Z",
     "iopub.status.busy": "2022-04-24T11:23:28.723957Z",
     "iopub.status.idle": "2022-04-24T11:23:28.734228Z",
     "shell.execute_reply": "2022-04-24T11:23:28.733244Z",
     "shell.execute_reply.started": "2022-04-24T11:23:28.724217Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:23:28.86094Z",
     "iopub.status.busy": "2022-04-24T11:23:28.860738Z",
     "iopub.status.idle": "2022-04-24T11:23:28.869177Z",
     "shell.execute_reply": "2022-04-24T11:23:28.868197Z",
     "shell.execute_reply.started": "2022-04-24T11:23:28.860916Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:23:33.738466Z",
     "iopub.status.busy": "2022-04-24T11:23:33.738187Z",
     "iopub.status.idle": "2022-04-24T11:23:33.8244Z",
     "shell.execute_reply": "2022-04-24T11:23:33.823675Z",
     "shell.execute_reply.started": "2022-04-24T11:23:33.738435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Analysing train dataframe attributes \n",
    "print('* Size of dataframe: {}\\n'.format(train_df.shape))\n",
    "print('* Datatype of columns are:\\n {}\\n'.format(train_df.dtypes))\n",
    "print('* Count of different categories:\\n {}\\n'.format(train_df['label'].value_counts()))\n",
    "print('* Number of NaNs among text are: {}\\n'.format(train_df['text'].isnull().sum()))\n",
    "\n",
    "# Converting text to string\n",
    "train_df['text'] = train_df['text'].astype(str)\n",
    "\n",
    "# Removing NaNs\n",
    "train_df = train_df.dropna(subset=['text'])\n",
    "print('NaNs are removed from the dataframe. Number of NaNs can be confirmed to be {}. The size of dataframe has reduced to {}'.format(train_df['text'].isnull().sum(), train_df.shape))\n",
    "\n",
    "# Analysing dev dataframe attributes \n",
    "print('* Size of dataframe: {}\\n'.format(dev_df.shape))\n",
    "print('* Datatype of columns are:\\n {}\\n'.format(dev_df.dtypes))\n",
    "print('* Count of different categories:\\n {}\\n'.format(dev_df['label'].value_counts()))\n",
    "print('* Number of NaNs among text are: {}\\n'.format(dev_df['text'].isnull().sum())) \n",
    "\n",
    "# Converting text to string\n",
    "dev_df['text'] = dev_df['text'].astype(str)\n",
    "\n",
    "# Removing NaNs\n",
    "dev_df = dev_df.dropna(subset=['text'])\n",
    "print('NaNs are removed from the dataframe. Number of NaNs can be confirmed to be {}. The size of dataframe has reduced to {}'.format(dev_df['text'].isnull().sum(), dev_df.shape))\n",
    "\n",
    "# Analysing test dataframe attributes \n",
    "print('* Size of dataframe: {}\\n'.format(test_df.shape))\n",
    "print('* Datatype of columns are:\\n {}\\n'.format(test_df.dtypes))\n",
    "print('* Count of different categories:\\n {}\\n'.format(test_df['label'].value_counts()))\n",
    "print('* Number of NaNs among text are: {}\\n'.format(test_df['text'].isnull().sum()))\n",
    "\n",
    "# Converting text to string\n",
    "test_df['text'] = test_df['text'].astype(str)\n",
    "\n",
    "# Removing NaNs\n",
    "test_df = test_df.dropna(subset=['text'])\n",
    "print('NaNs are removed from the dataframe. Number of NaNs can be confirmed to be {}. The size of dataframe has reduced to {}'.format(test_df['text'].isnull().sum(), test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:24:00.482542Z",
     "iopub.status.busy": "2022-04-24T11:24:00.482218Z",
     "iopub.status.idle": "2022-04-24T11:24:00.75164Z",
     "shell.execute_reply": "2022-04-24T11:24:00.750933Z",
     "shell.execute_reply.started": "2022-04-24T11:24:00.482504Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting label value counts\n",
    "train_df.groupby('label').count().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:24:26.142292Z",
     "iopub.status.busy": "2022-04-24T11:24:26.142039Z",
     "iopub.status.idle": "2022-04-24T11:24:26.409029Z",
     "shell.execute_reply": "2022-04-24T11:24:26.408337Z",
     "shell.execute_reply.started": "2022-04-24T11:24:26.142263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting word lenghts of train text\n",
    "train_word_length = [len(x) for x in train_df['text']]\n",
    "plt.plot(train_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:24:37.334108Z",
     "iopub.status.busy": "2022-04-24T11:24:37.333852Z",
     "iopub.status.idle": "2022-04-24T11:24:37.52347Z",
     "shell.execute_reply": "2022-04-24T11:24:37.5228Z",
     "shell.execute_reply.started": "2022-04-24T11:24:37.334079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting label value counts\n",
    "dev_df.groupby('label').count().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:24:38.668667Z",
     "iopub.status.busy": "2022-04-24T11:24:38.667951Z",
     "iopub.status.idle": "2022-04-24T11:24:38.891408Z",
     "shell.execute_reply": "2022-04-24T11:24:38.890723Z",
     "shell.execute_reply.started": "2022-04-24T11:24:38.668626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting word lenghts of train text\n",
    "dev_word_length = [len(x) for x in dev_df['text']]\n",
    "plt.plot(dev_word_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:24:40.552045Z",
     "iopub.status.busy": "2022-04-24T11:24:40.551783Z",
     "iopub.status.idle": "2022-04-24T11:24:40.742063Z",
     "shell.execute_reply": "2022-04-24T11:24:40.741403Z",
     "shell.execute_reply.started": "2022-04-24T11:24:40.552015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting label value counts\n",
    "test_df.groupby('label').count().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:24:41.989454Z",
     "iopub.status.busy": "2022-04-24T11:24:41.989177Z",
     "iopub.status.idle": "2022-04-24T11:24:42.191078Z",
     "shell.execute_reply": "2022-04-24T11:24:42.190352Z",
     "shell.execute_reply.started": "2022-04-24T11:24:41.989423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting word lenghts of train text\n",
    "test_word_length = [len(x) for x in test_df['text']]\n",
    "plt.plot(test_word_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "latter-checkout"
   },
   "source": [
    "# 2. Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:25:00.482927Z",
     "iopub.status.busy": "2022-04-24T11:25:00.482459Z",
     "iopub.status.idle": "2022-04-24T11:25:00.486621Z",
     "shell.execute_reply": "2022-04-24T11:25:00.485931Z",
     "shell.execute_reply.started": "2022-04-24T11:25:00.482893Z"
    },
    "id": "B79R84lBEjq1"
   },
   "outputs": [],
   "source": [
    "# Declaring train labels\n",
    "train_labels = train_df['label']\n",
    "valid_labels = dev_df['label']\n",
    "test_labels = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:25:02.809202Z",
     "iopub.status.busy": "2022-04-24T11:25:02.808918Z",
     "iopub.status.idle": "2022-04-24T11:25:02.840984Z",
     "shell.execute_reply": "2022-04-24T11:25:02.839589Z",
     "shell.execute_reply.started": "2022-04-24T11:25:02.809172Z"
    },
    "id": "functioning-anniversary",
    "outputId": "159fe6d6-6924-4ae2-be2d-f75b967ca5bb"
   },
   "outputs": [],
   "source": [
    "# Converting labels to numerical features\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_labels = le.transform(train_labels)\n",
    "valid_labels = le.transform(valid_labels)\n",
    "test_labels = le.transform(test_labels)\n",
    "\n",
    "print(le.classes_)\n",
    "print(np.unique(train_labels, return_counts=True))\n",
    "print(np.unique(valid_labels, return_counts=True))\n",
    "print(np.unique(test_labels, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:25:12.273335Z",
     "iopub.status.busy": "2022-04-24T11:25:12.27302Z",
     "iopub.status.idle": "2022-04-24T11:25:13.131439Z",
     "shell.execute_reply": "2022-04-24T11:25:13.130704Z",
     "shell.execute_reply.started": "2022-04-24T11:25:12.273301Z"
    },
    "id": "aging-legislation"
   },
   "outputs": [],
   "source": [
    "# Changing labels to categorical features\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "train_labels = to_categorical(np.asarray(train_labels))\n",
    "valid_labels = to_categorical(np.asarray(valid_labels))\n",
    "test_labels = to_categorical(np.array(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:29:04.861912Z",
     "iopub.status.busy": "2022-04-24T11:29:04.861316Z",
     "iopub.status.idle": "2022-04-24T11:29:04.875317Z",
     "shell.execute_reply": "2022-04-24T11:29:04.874401Z",
     "shell.execute_reply.started": "2022-04-24T11:29:04.861877Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_count = train_df['label'].value_counts()\n",
    "labels_count = len(labels_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYsRdnbBJElq"
   },
   "source": [
    "# 3. Tokenizing Sentences and Fixing Sentence Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:25:55.687567Z",
     "iopub.status.busy": "2022-04-24T11:25:55.687274Z",
     "iopub.status.idle": "2022-04-24T11:26:21.663229Z",
     "shell.execute_reply": "2022-04-24T11:26:21.662504Z",
     "shell.execute_reply.started": "2022-04-24T11:25:55.687533Z"
    },
    "id": "xoWD8JOzJQ5f",
    "outputId": "1afad274-124c-40a8-b206-2a476c2d5ec4"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Defining training parameters\n",
    "max_sequence_length = 170   \n",
    "max_words = 30000   \n",
    "\n",
    "# Tokenizing tweets/sentences wrt num_words\n",
    "tokenizer = Tokenizer(num_words = max_words)  # Selects most frequent words \n",
    "tokenizer.fit_on_texts(train_df.text)      # Develops internal vocab based on training text\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df.text)  # converts text to sequence\n",
    "\n",
    "valid_sequences = tokenizer.texts_to_sequences(dev_df.text)\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:26:24.444771Z",
     "iopub.status.busy": "2022-04-24T11:26:24.444206Z",
     "iopub.status.idle": "2022-04-24T11:26:25.210047Z",
     "shell.execute_reply": "2022-04-24T11:26:25.209324Z",
     "shell.execute_reply.started": "2022-04-24T11:26:24.444732Z"
    },
    "id": "djBvMk-BJQyg",
    "outputId": "5250a5a1-9be9-4705-ad8e-8e8ef432e135"
   },
   "outputs": [],
   "source": [
    "# Fixing the sequence length \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "train_data = pad_sequences(train_sequences, maxlen = max_sequence_length)\n",
    "valid_data = pad_sequences(valid_sequences, maxlen = max_sequence_length)\n",
    "test_data = pad_sequences(test_sequences, maxlen = max_sequence_length)\n",
    "train_data.shape, valid_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "honey-orbit"
   },
   "source": [
    "# 4. Bi-LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wE-GkxBSUVSc"
   },
   "source": [
    "## # 4.1 Declaring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:26:39.558845Z",
     "iopub.status.busy": "2022-04-24T11:26:39.558295Z",
     "iopub.status.idle": "2022-04-24T11:26:39.562881Z",
     "shell.execute_reply": "2022-04-24T11:26:39.562029Z",
     "shell.execute_reply.started": "2022-04-24T11:26:39.558808Z"
    },
    "id": "IfzH9ISoBDji"
   },
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "embedding_dim = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T11:26:49.938467Z",
     "iopub.status.busy": "2022-04-24T11:26:49.938196Z",
     "iopub.status.idle": "2022-04-24T11:26:49.949645Z",
     "shell.execute_reply": "2022-04-24T11:26:49.948787Z",
     "shell.execute_reply.started": "2022-04-24T11:26:49.938435Z"
    },
    "id": "compact-functionality"
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D, Conv1D, SimpleRNN\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras.layers import Dense, Input, Input, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:36:57.568882Z",
     "iopub.status.busy": "2022-04-24T12:36:57.568618Z",
     "iopub.status.idle": "2022-04-24T12:36:57.968868Z",
     "shell.execute_reply": "2022-04-24T12:36:57.968156Z",
     "shell.execute_reply.started": "2022-04-24T12:36:57.568847Z"
    },
    "id": "regular-neighborhood",
    "outputId": "c3fb74eb-3329-41c9-b2ae-9357c2db2df3"
   },
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, \n",
    "                   embedding_dim,\n",
    "                   input_length = max_sequence_length))\n",
    "\n",
    "# Bidirectional LSTM \n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True, dropout=0.4, recurrent_dropout=0)))   \n",
    "\n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "model.add(Dense(labels_count,activation='softmax'))  \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzO3QaesUM13"
   },
   "source": [
    "## # 4.2 Passing Data Through Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:37:00.263773Z",
     "iopub.status.busy": "2022-04-24T12:37:00.263508Z",
     "iopub.status.idle": "2022-04-24T12:37:00.273366Z",
     "shell.execute_reply": "2022-04-24T12:37:00.272674Z",
     "shell.execute_reply.started": "2022-04-24T12:37:00.263743Z"
    },
    "id": "listed-christianity"
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer='Adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:37:05.304361Z",
     "iopub.status.busy": "2022-04-24T12:37:05.303819Z",
     "iopub.status.idle": "2022-04-24T12:37:05.308941Z",
     "shell.execute_reply": "2022-04-24T12:37:05.308042Z",
     "shell.execute_reply.started": "2022-04-24T12:37:05.304324Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_filepath = '/model'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:37:07.416189Z",
     "iopub.status.busy": "2022-04-24T12:37:07.415928Z",
     "iopub.status.idle": "2022-04-24T12:48:21.788542Z",
     "shell.execute_reply": "2022-04-24T12:48:21.787784Z",
     "shell.execute_reply.started": "2022-04-24T12:37:07.416159Z"
    },
    "id": "genuine-millennium",
    "outputId": "8a58c5f3-07c8-4e95-e1a0-11a685210021"
   },
   "outputs": [],
   "source": [
    "# training and validating model \n",
    "# history = model.fit(train_data, train_labels, batch_size=48, epochs= 20, class_weight = class_weight, validation_data=(test_data, test_labels)) # best 89(now) or 48 or 60 epochs # default epochs = 23 # batch_size changed to 1 (takes 2.30hrs) from 16\n",
    "# best 89(now) or 48 or 60 epochs # default epochs = 23 # batch_size changed to 1 (takes 2.30hrs) from 16\n",
    "history = model.fit(train_data, train_labels, batch_size=48, epochs= 50, validation_data=(valid_data, valid_labels), callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:21:01.289051Z",
     "iopub.status.busy": "2022-04-24T12:21:01.288765Z",
     "iopub.status.idle": "2022-04-24T12:21:12.104988Z",
     "shell.execute_reply": "2022-04-24T12:21:12.104234Z",
     "shell.execute_reply.started": "2022-04-24T12:21:01.289022Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 4.3 Evaluating the model with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:58:26.46917Z",
     "iopub.status.busy": "2022-04-24T12:58:26.468866Z",
     "iopub.status.idle": "2022-04-24T12:58:27.443899Z",
     "shell.execute_reply": "2022-04-24T12:58:27.442965Z",
     "shell.execute_reply.started": "2022-04-24T12:58:26.469137Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:58:28.453857Z",
     "iopub.status.busy": "2022-04-24T12:58:28.45334Z",
     "iopub.status.idle": "2022-04-24T12:58:30.248343Z",
     "shell.execute_reply": "2022-04-24T12:58:30.247549Z",
     "shell.execute_reply.started": "2022-04-24T12:58:28.453816Z"
    },
    "id": "heard-mentor"
   },
   "outputs": [],
   "source": [
    "# Prediction on Test Data\n",
    "predicted_bi_lstm = model.predict(test_data)\n",
    "predicted_bi_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:58:37.418212Z",
     "iopub.status.busy": "2022-04-24T12:58:37.417482Z",
     "iopub.status.idle": "2022-04-24T12:58:37.421997Z",
     "shell.execute_reply": "2022-04-24T12:58:37.42121Z",
     "shell.execute_reply.started": "2022-04-24T12:58:37.418175Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_labels = np.argmax(predicted_bi_lstm.round(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:58:39.705868Z",
     "iopub.status.busy": "2022-04-24T12:58:39.705238Z",
     "iopub.status.idle": "2022-04-24T12:58:39.709591Z",
     "shell.execute_reply": "2022-04-24T12:58:39.70874Z",
     "shell.execute_reply.started": "2022-04-24T12:58:39.705835Z"
    }
   },
   "outputs": [],
   "source": [
    "actual_labels = np.argmax(test_labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:58:40.983626Z",
     "iopub.status.busy": "2022-04-24T12:58:40.983059Z",
     "iopub.status.idle": "2022-04-24T12:58:40.989084Z",
     "shell.execute_reply": "2022-04-24T12:58:40.988175Z",
     "shell.execute_reply.started": "2022-04-24T12:58:40.983585Z"
    }
   },
   "outputs": [],
   "source": [
    "classification_results = []\n",
    "for i in range(5):\n",
    "    predict_label = pred_labels[i]\n",
    "    actual_label = actual_labels[i]\n",
    "    text = test_df['text'][i]\n",
    "    classification_results.append({'actual': actual_label, 'predict': predict_label, 'sentence': text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:58:41.808643Z",
     "iopub.status.busy": "2022-04-24T12:58:41.807894Z",
     "iopub.status.idle": "2022-04-24T12:58:41.81344Z",
     "shell.execute_reply": "2022-04-24T12:58:41.812413Z",
     "shell.execute_reply.started": "2022-04-24T12:58:41.808603Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('classification_results.pkl', 'wb') as fp:\n",
    "    pickle.dump(classification_results, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T12:59:59.380538Z",
     "iopub.status.busy": "2022-04-24T12:59:59.380233Z",
     "iopub.status.idle": "2022-04-24T13:00:04.896148Z",
     "shell.execute_reply": "2022-04-24T13:00:04.895412Z",
     "shell.execute_reply.started": "2022-04-24T12:59:59.380495Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T13:00:04.956177Z",
     "iopub.status.busy": "2022-04-24T13:00:04.95545Z",
     "iopub.status.idle": "2022-04-24T13:00:05.875779Z",
     "shell.execute_reply": "2022-04-24T13:00:05.874952Z",
     "shell.execute_reply.started": "2022-04-24T13:00:04.956141Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 5.1 Model Performance Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T13:00:08.018159Z",
     "iopub.status.busy": "2022-04-24T13:00:08.017902Z",
     "iopub.status.idle": "2022-04-24T13:00:08.055343Z",
     "shell.execute_reply": "2022-04-24T13:00:08.054258Z",
     "shell.execute_reply.started": "2022-04-24T13:00:08.01813Z"
    }
   },
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = score(test_labels, predicted_bi_lstm.round())\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))\n",
    "print('################################')\n",
    "print(sklearn.metrics.classification_report(test_labels, predicted_bi_lstm.round()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 5.2 Model Performance with Epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T13:00:15.796938Z",
     "iopub.status.busy": "2022-04-24T13:00:15.796686Z",
     "iopub.status.idle": "2022-04-24T13:00:16.195971Z",
     "shell.execute_reply": "2022-04-24T13:00:16.195301Z",
     "shell.execute_reply.started": "2022-04-24T13:00:15.79691Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_plot(history):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
    "    \n",
    "    fig.suptitle('Model Performance with Epochs', fontsize = 16)\n",
    "    # Subplot 1 \n",
    "    ax[0].plot(history.history['accuracy'])\n",
    "    ax[0].plot(history.history['val_accuracy'])\n",
    "    ax[0].set_title('Model Accuracy', fontsize = 14)\n",
    "    ax[0].set_xlabel('Epochs', fontsize = 12)\n",
    "    ax[0].set_ylabel('Accuracy', fontsize = 12)\n",
    "    ax[0].legend(['train', 'validation'], loc='best')\n",
    "    \n",
    "    # Subplot 2\n",
    "    ax[1].plot(history.history['loss'])\n",
    "    ax[1].plot(history.history['val_loss'])\n",
    "    ax[1].set_title('Model Loss', fontsize = 14)\n",
    "    ax[1].set_xlabel('Epochs', fontsize = 12)\n",
    "    ax[1].set_ylabel('Loss', fontsize = 12)\n",
    "    ax[1].legend(['train', 'validation'], loc='best')\n",
    "    \n",
    "    \n",
    "accuracy_plot(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## # 5.3 Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-24T13:00:17.154157Z",
     "iopub.status.busy": "2022-04-24T13:00:17.153587Z",
     "iopub.status.idle": "2022-04-24T13:00:19.288011Z",
     "shell.execute_reply": "2022-04-24T13:00:19.287344Z",
     "shell.execute_reply.started": "2022-04-24T13:00:17.154123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declaring function for plotting confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_cm(model, test_data, test_labels):\n",
    "    \n",
    "    products = train_df['label'].unique()\n",
    "        \n",
    "    # Calculate predictions\n",
    "    pred = model.predict(test_data)\n",
    "    \n",
    "    # Declaring confusion matrix\n",
    "    cm = confusion_matrix(np.argmax(np.array(test_labels),axis=1), np.argmax(pred, axis=1))\n",
    "    \n",
    "    # Heat map labels\n",
    "\n",
    "    group_counts = ['{0:0.0f}'.format(value) for value in cm.flatten()]\n",
    "    group_percentages = ['{0:.2%}'.format(value) for value in cm.flatten()/np.sum(cm)]\n",
    "    \n",
    "    labels = [f\"{v2}\\n{v3}\" for v2, v3 in zip(group_counts, group_percentages)]\n",
    "    labels = np.asarray(labels).reshape(labels_count,labels_count)\n",
    "\n",
    "    # Plotting confusion matrix\n",
    "    plt.figure(figsize=(12,8))\n",
    "    \n",
    "    sns.heatmap(cm, cmap=plt.cm.Blues, annot=labels, annot_kws={\"size\": 15}, fmt = '',\n",
    "                xticklabels = products,\n",
    "                yticklabels = products)\n",
    "    \n",
    "    plt.xticks(fontsize = 12)\n",
    "    plt.yticks(fontsize = 12, rotation = 'horizontal')\n",
    "    plt.title('Confusion Matrix\\n', fontsize=19)\n",
    "    plt.xlabel('Predicted Labels', fontsize=17)\n",
    "    plt.ylabel('Actual Labels', fontsize=17)\n",
    "    \n",
    "plot_cm(model, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. References\n",
    "\n",
    "1. NLP Implementation: https://www.kaggle.com/the0electronic0guy/nlp-with-disaster-tweets\n",
    "\n",
    "2. NLP Book: Kulkarni, Akshay, and Adarsha Shivananda. Natural language processing recipes. Apress, 2019.\n",
    "\n",
    "3. LSTM: https://www.kaggle.com/kritanjalijain/twitter-sentiment-analysis-lstm\n",
    "\n",
    "4. Bi-LSTM: https://www.kaggle.com/kritanjalijain/twitter-sentiment-analysis-lstm-2#Bidirectional-LSTM-Using-NN \n",
    "\n",
    "5. Bi-LSTM: https://www.kaggle.com/eashish/bidirectional-gru-with-convolution\n",
    "\n",
    "6. Bi-LSTM: https://www.kaggle.com/victorbnnt/classification-using-lstm-85-accuracy\n",
    "\n",
    "7. Imbalanced Datasets: https://towardsdatascience.com/yet-another-twitter-sentiment-analysis-part-1-tackling-class-imbalance-4d7a7f717d44\n",
    "\n",
    "8. Multiclass Classification: https://towardsdatascience.com/machine-learning-multiclass-classification-with-imbalanced-data-set-29f6a177c1a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
